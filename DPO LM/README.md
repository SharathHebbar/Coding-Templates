# Direct Preference Optimization of Language Models

Quick Template for DPO