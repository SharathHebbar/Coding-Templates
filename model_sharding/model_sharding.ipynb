{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30646,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title # Installing Libraries\n",
        "!pip install sentencepiece accelerate"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-02-06T15:48:53.036582Z",
          "iopub.execute_input": "2024-02-06T15:48:53.037090Z",
          "iopub.status.idle": "2024-02-06T15:49:10.415016Z",
          "shell.execute_reply.started": "2024-02-06T15:48:53.037045Z",
          "shell.execute_reply": "2024-02-06T15:49:10.413428Z"
        },
        "trusted": true,
        "cellView": "form",
        "id": "N7RJRt28yLNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Importing Libraries\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from accelerate import Accelerator, load_checkpoint_and_dispatch\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T15:49:10.418668Z",
          "iopub.execute_input": "2024-02-06T15:49:10.419142Z",
          "iopub.status.idle": "2024-02-06T15:49:18.790768Z",
          "shell.execute_reply.started": "2024-02-06T15:49:10.419106Z",
          "shell.execute_reply": "2024-02-06T15:49:18.789854Z"
        },
        "trusted": true,
        "cellView": "form",
        "id": "ieIjD5B6yLNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# @title ## Your Model and Dataset\n",
        "\n",
        "# @markdown ### Model\n",
        "# @markdown Select your model\n",
        "\n",
        "model_name = \"tiiuae/falcon-7b-instruct\" # @param {type:\"string\"}\n",
        "low_cpu_mem_usage = True # @param {type:\"boolean\"}\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=low_cpu_mem_usage,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "# @markdown <br>\n",
        "# @markdown  <h2> Save your model locally </h2>\n",
        "save_directory=\"/content/model\"  # @param {type:\"string\"}\n",
        "max_shard = 100 # @param {type:\"integer\"}\n",
        "size = \"MB\" # @param [\"MB\", \"GB\"]\n",
        "max_shard_size = str(max_shard) + str(size)\n",
        "model.save_pretrained(save_directory, max_shard_size=max_shard_size)\n",
        "\n",
        "accelerator = Accelerator()\n",
        "accelerator.save_model(model=model, save_directory=save_directory, max_shard_size=max_shard_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T15:49:18.814773Z",
          "iopub.execute_input": "2024-02-06T15:49:18.815529Z",
          "iopub.status.idle": "2024-02-06T15:51:42.383894Z",
          "shell.execute_reply.started": "2024-02-06T15:49:18.815494Z",
          "shell.execute_reply": "2024-02-06T15:51:42.381519Z"
        },
        "trusted": true,
        "cellView": "form",
        "id": "VnXgrVm8yLNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Load Sharded Model\n",
        "device_map={\"\":'cpu'}\n",
        "\n",
        "model = load_checkpoint_and_dispatch(\n",
        "    model,\n",
        "    checkpoint=save_directory,\n",
        "    device_map=device_map,\n",
        "    no_split_module_classes=[\"Block\"]\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "cellView": "form",
        "id": "bglC2SNzyLNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Pushing to Hub\n",
        "MODEL_PATH = \"Sharathhebbar24/falcon-7b-instruct_sharded\" # @param {type:\"string\"}\n",
        "HF_TOKEN = \"\" # @param {type:\"string\"}\n",
        "\n",
        "tokenizer.push_to_hub(\n",
        "    MODEL_PATH,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "\n",
        "model.push_to_hub(\n",
        "    MODEL_PATH,\n",
        "    token=HF_TOKEN\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T15:53:07.632889Z",
          "iopub.execute_input": "2024-02-06T15:53:07.633457Z",
          "iopub.status.idle": "2024-02-06T15:53:07.639876Z",
          "shell.execute_reply.started": "2024-02-06T15:53:07.633416Z",
          "shell.execute_reply": "2024-02-06T15:53:07.638352Z"
        },
        "trusted": true,
        "cellView": "form",
        "id": "cD9wPZYoyLNK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}